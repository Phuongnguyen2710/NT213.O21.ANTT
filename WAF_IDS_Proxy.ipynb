{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "M07xXELo353q"
      },
      "outputs": [],
      "source": [
        "from http.server import SimpleHTTPRequestHandler, HTTPServer, BaseHTTPRequestHandler\n",
        "import sys\n",
        "import requests\n",
        "from urllib.parse import urljoin, unquote\n",
        "import urllib.parse\n",
        "import numpy as np\n",
        "import keras \n",
        "from keras.models import  load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.3.3)\n",
            "Requirement already satisfied: absl-py in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (1.24.3)\n",
            "Requirement already satisfied: rich in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (0.0.7)\n",
            "Requirement already satisfied: h5py in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (3.10.0)\n",
            "Requirement already satisfied: optree in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optree->keras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib.parse\n",
        "\n",
        "# def url_decode(encoded_URL):\n",
        "#     \"\"\"\n",
        "#     Decode the URL encoded string.\n",
        "    \n",
        "#     Parameters:\n",
        "#         encoded_URL (str): The URL encoded string.\n",
        "        \n",
        "#     Returns:\n",
        "#         str: The decoded URL string.\n",
        "#     \"\"\"\n",
        "#     if isinstance(encoded_URL, str):  # Kiểm tra nếu tham số là một chuỗi\n",
        "#         if encoded_URL != \"/\":  # Kiểm tra nếu giá trị không phải là \"/\"\n",
        "#             decoded_url = urllib.parse.unquote(encoded_URL)\n",
        "#             return decoded_url\n",
        "#         else:\n",
        "#             return encoded_URL  # Trả về giá trị gốc nếu là \"/\"\n",
        "#     else:\n",
        "#         # Trả về None hoặc thông báo lỗi tùy vào yêu cầu cụ thể của bạn\n",
        "#         return None  # Hoặc raise TypeError(\"Invalid input type: expected str, got {type(encoded_URL)}\")\n",
        "\n",
        "\n",
        "# def load_data(urls, max_length=1000):\n",
        "#     for url in urls:\n",
        "#         if url != '/':  # Kiểm tra nếu giá trị không phải là '/'\n",
        "#             try:\n",
        "#                 url_lower = str(url).lower()\n",
        "#             except AttributeError:  # Bắt ngoại lệ nếu giá trị không thể chuyển đổi thành chuỗi\n",
        "#                 print(f\"Skipping lowercase conversion for value: {url}\")\n",
        "#                 url_lower = url\n",
        "#         else:\n",
        "#             url_lower = url  # Giữ nguyên giá trị nếu là '/'\n",
        "#     url_list = []\n",
        "#     for url in urls:\n",
        "#         # url decode\n",
        "#         decoded_url = url_decode(url)\n",
        "#         # unicode encode\n",
        "#         encoded_url = [ord(x) for x in str(decoded_url).strip()]\n",
        "#         encoded_url = encoded_url[:max_length]\n",
        "#         url_len = len(encoded_url)\n",
        "#         if url_len < max_length:\n",
        "#             # zero padding\n",
        "#             encoded_url += ([0] * (max_length - url_len))\n",
        "#         url_list.append((encoded_url))\n",
        "#     # convert to numpy array\n",
        "#     url_list = np.array(url_list)\n",
        "#     return url_list\n",
        "\n",
        "\n",
        "def load_data(url, max_length=1000):\n",
        "    # Chuyển đổi URL thành chữ thường\n",
        "    url = url.lower()\n",
        "    \n",
        "    # Giải mã URL\n",
        "    #decoded_url = url_decode(url)\n",
        "    decoded_url = unquote(url)\n",
        "    # Mã hóa Unicode\n",
        "    encoded_url = [ord(x) for x in str(decoded_url).strip()]\n",
        "    \n",
        "    # Cắt ngắn URL nếu nó quá dài\n",
        "    encoded_url = encoded_url[:max_length]\n",
        "    \n",
        "    # Thêm đệm 0 nếu cần\n",
        "    url_len = len(encoded_url)\n",
        "    if url_len < max_length:\n",
        "        encoded_url += [0] * (max_length - url_len)\n",
        "    \n",
        "    # Chuyển đổi thành mảng numpy và trả về\n",
        "    return np.array([encoded_url])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "#Best capec: architectureA: 8 - architecture B: 2,3,4,5\n",
        "#Best csic: architectureA: 6 - architecture B: \n",
        "#path = r\"C:\\Users\\ASUS\\Desktop\\Đồ án BMW\\NT213.O21.ANTT\\CAPEC-dataset\\ArchitectA\\Testcase8\\model.h5\"\n",
        "#path = r\"C:\\Users\\ASUS\\Desktop\\Đồ án BMW\\NT213.O21.ANTT\\CSIC-2010-dataset\\Architecture B\\TestCase[2,3,4,5]\\model.h5\"\n",
        "path = r\"C:\\Users\\ASUS\\Desktop\\Đồ án BMW\\NT213.O21.ANTT\\CSIC-2010-dataset\\Architecture A\\TestCase4\\model.h5\"\n",
        "#path = r\"C:\\Users\\ASUS\\Desktop\\Đồ án BMW\\NT213.O21.ANTT\\CAPEC-dataset\\ArchitectB\\Test case [2,3,4,5]\\model.h5\"\n",
        "model = load_model(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def predict(model ,url):\n",
        "#     y_pred = model.predict(url)\n",
        "#     print(y_pred)\n",
        "#     return 1 if y_pred < 0.5 else 0\n",
        "    # return y_pred\n",
        "    \n",
        "    \n",
        "def predict(model ,url):\n",
        "    y_pred = model.predict(url)\n",
        "    print(y_pred)\n",
        "    return 1 if y_pred >= 0.5 else 0\n",
        "    #return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "fsyH3Lx_1XH6"
      },
      "outputs": [],
      "source": [
        "# class SimpleHttpProxy(BaseHTTPRequestHandler):\n",
        "#     proxy_routes = {}\n",
        "\n",
        "#     @classmethod\n",
        "#     def set_routes(cls, proxy_routes):\n",
        "#         cls.proxy_routes = proxy_routes\n",
        "\n",
        "#     def do_GET(self):\n",
        "#         try:\n",
        "#             proxy_route = self.proxy_routes.get('proxy_route')\n",
        "#             if proxy_route:\n",
        "#                 target_url = urljoin(proxy_route, self.path)\n",
        "#                 #print(load_data(target_url))\n",
        "#                 y_pred = predict(model, load_data(target_url))\n",
        "#                 print(y_pred)\n",
        "#                 response = requests.get(target_url)\n",
        "#                 self.send_response(response.status_code)\n",
        "#                 self.send_header('Content-type', 'text/html')\n",
        "#                 self.end_headers()\n",
        "#                 self.wfile.write(response.content)\n",
        "#             else:\n",
        "#                 self.send_error(404, 'Proxy route not found')\n",
        "#         except Exception as e:\n",
        "#             self.send_error(500, str(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def main():\n",
        "#     # Set proxy route\n",
        "#     SimpleHttpProxy.set_routes({'proxy_route': 'http://demo.testfire.net/'})\n",
        "    \n",
        "#     # Start HTTP server\n",
        "#     server_address = ('127.0.0.1', 12345)\n",
        "#     httpd = HTTPServer(server_address, SimpleHttpProxy)\n",
        "#     print(f'Starting HTTP Proxy server on {server_address[0]}:{server_address[1]}')\n",
        "#     try:\n",
        "#         httpd.serve_forever()\n",
        "#     except KeyboardInterrupt:\n",
        "#         print('Keyboard interrupt, exiting.')\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Danh sách các URL cần thêm vào whitelist\n",
        "# urls = [\n",
        "#     \"https://example.com/image1.jpg\",\n",
        "#     \"https://example.com/image2.jpg\",\n",
        "#     \"https://example.com/image3.jpg\",\n",
        "#     # Thêm các URL khác nếu cần\n",
        "# ]\n",
        "\n",
        "# # Tên tệp whitelist\n",
        "# whitelist_file = \"whitelist.txt\"\n",
        "\n",
        "# # Ghi các URL vào tệp whitelist\n",
        "# with open(whitelist_file, \"w\") as file:\n",
        "#     for url in urls:\n",
        "#         file.write(url + \"\\n\")\n",
        "\n",
        "# print(\"Whitelist đã được tạo thành công và lưu vào file:\", whitelist_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def check_url_in_whitelist(url_param, whitelist_file):\n",
        "#     \"\"\"\n",
        "#     Hàm để kiểm tra xem một URL có trong whitelist hay không.\n",
        "\n",
        "#     Tham số:\n",
        "#     - url_param: URL cần kiểm tra\n",
        "#     - whitelist_file: Tệp whitelist chứa danh sách các URL được phép\n",
        "\n",
        "#     Trả về:\n",
        "#     - True nếu URL tồn tại trong whitelist, False nếu không.\n",
        "#     \"\"\"\n",
        "#     # Mở tệp whitelist và đọc nội dung\n",
        "#     with open(whitelist_file, \"r\") as file:\n",
        "#         # Đọc từng dòng trong tệp\n",
        "#         for line in file:\n",
        "#             # Loại bỏ khoảng trắng và ký tự xuống dòng từ mỗi dòng\n",
        "#             whitelist_url = line.strip()\n",
        "#             # Kiểm tra xem URL truyền vào có trùng với URL trong whitelist không\n",
        "#             if url_param == whitelist_url:\n",
        "#                 return True  # Trả về True nếu có trùng\n",
        "#     # Trả về False nếu không có URL nào trong whitelist trùng khớp\n",
        "#     return False\n",
        "\n",
        "\n",
        "# whitelist_file = \"whitelist.txt\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting HTTP Proxy server on 127.0.0.1:8080\n",
            "Keyboard interrupt, exiting.\n"
          ]
        }
      ],
      "source": [
        "from http.server import BaseHTTPRequestHandler\n",
        "from urllib.parse import urljoin\n",
        "import requests\n",
        "import re\n",
        "\n",
        "class SimpleHttpProxy(BaseHTTPRequestHandler):\n",
        "    proxy_routes = {}\n",
        "    global_cookies = {}\n",
        "\n",
        "    @classmethod\n",
        "    def set_routes(cls, proxy_routes):\n",
        "        cls.proxy_routes = proxy_routes\n",
        "\n",
        "    @staticmethod\n",
        "    def check_url_in_whitelist(url_param, whitelist_file):\n",
        "        \"\"\"\n",
        "        Hàm để kiểm tra xem một URL có trong whitelist hay không.\n",
        "\n",
        "        Tham số:\n",
        "        - url_param: URL cần kiểm tra\n",
        "        - whitelist_file: Tệp whitelist chứa danh sách các URL được phép\n",
        "\n",
        "        Trả về:\n",
        "        - True nếu URL tồn tại trong whitelist, False nếu không.\n",
        "        \"\"\"\n",
        "        with open(whitelist_file, \"r\") as file:\n",
        "            for line in file:\n",
        "                whitelist_url = line.strip()\n",
        "                if url_param == whitelist_url:\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def do_GET(self):\n",
        "        try:\n",
        "            proxy_route = self.proxy_routes.get('proxy_route')\n",
        "            \n",
        "            if proxy_route:\n",
        "                target_url = urljoin(proxy_route, self.path)\n",
        "                \n",
        "                if self.check_url_in_whitelist(target_url, \"whitelist.txt\"):\n",
        "                    y_pred = 0\n",
        "                elif \"dvwa/phpinfo.php\" in target_url:\n",
        "                    y_pred = 0\n",
        "                else:\n",
        "                    y_pred = predict(model, load_data(target_url))\n",
        "                print(f\"Prediction cho {target_url}\", y_pred)\n",
        "                if y_pred == 1:\n",
        "                        self.send_response(403)  # Gửi mã trạng thái 403 Forbidden\n",
        "                        self.send_header('Content-type', 'text/html')\n",
        "                        self.end_headers()\n",
        "                        html_content = '''<!DOCTYPE html>\n",
        "                                            <html lang=\"en\">\n",
        "                                            <head>\n",
        "                                                <meta charset=\"UTF-8\">\n",
        "                                                <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "                                                <title>403 Forbidden</title>\n",
        "                                            </head>\n",
        "                                            <body>\n",
        "                                                <h1>403 Forbidden</h1>\n",
        "                                                <p>Truy cập bị từ chối. Vui lòng liên hệ với quản trị viên.</p>\n",
        "                                            </body>\n",
        "                                            </html>'''\n",
        "                        self.wfile.write(html_content.encode('utf-8'))\n",
        "                        return  # Dừng xử lý và trả về  \n",
        "                if self.global_cookies:\n",
        "                    response = requests.get(target_url, allow_redirects=False, cookies=self.global_cookies)\n",
        "                else:\n",
        "                    response = requests.get(target_url, allow_redirects=False)\n",
        "                \n",
        "                if response.status_code in [301, 302, 303, 307, 308]:\n",
        "                    redirect_url = response.headers['Location']\n",
        "                    response = requests.get(redirect_url)\n",
        "                \n",
        "                self.send_response(response.status_code)\n",
        "                content_type = response.headers.get('Content-Type', 'text/html')\n",
        "                self.send_header('Content-type', content_type)\n",
        "                self.end_headers()\n",
        "                self.wfile.write(response.content)\n",
        "                \n",
        "                                \n",
        "                # self.send_response(response.status_code)\n",
        "                # content_type = response.headers.get('Content-Type', 'text/html')\n",
        "                # self.send_header('Content-type', content_type)\n",
        "                # self.end_headers()\n",
        "                # self.wfile.write(response.content)\n",
        "                \n",
        "            else:\n",
        "                self.send_error(404, 'Proxy route not found')\n",
        "        except Exception as e:\n",
        "            self.send_error(500, str(e))\n",
        "\n",
        "    def do_POST(self):\n",
        "        try:\n",
        "            content_length = int(self.headers['Content-Length'])\n",
        "            resp = requests.get(\"http://192.168.124.173/dvwa/login.php\")\n",
        "            print(resp.text)    \n",
        "            post_data = self.rfile.read(content_length)\n",
        "            proxy_route = self.proxy_routes.get('proxy_route')\n",
        "            if proxy_route:\n",
        "                target_url = urljoin(proxy_route, self.path)\n",
        "                requests.get(target_url, params=None, headers=None, cookies=None, auth=None, timeout=None)\n",
        "                if self.check_url_in_whitelist(target_url, \"whitelist.txt\") and post_data is None:\n",
        "                    y_pred = 0\n",
        "                    \n",
        "                elif \"dvwa/phpinfo.php\" in target_url:\n",
        "                    y_pred = 0\n",
        "                else:\n",
        "                    #payload_to_pred = target_url.rsplit('/') + '?'+ post_data.decode('utf-8', errors='ignore') \n",
        "                    #print(\"TEST\",payload_to_pred)\n",
        "                    #luc dau la target url\n",
        "                    y_pred = predict(model, load_data(target_url+'?'+ post_data.decode('utf-8', errors='ignore')))\n",
        "                    # Kiểm tra nếu dự đoán vượt quá ngưỡng 0.5\n",
        " \n",
        "                print(f\"Prediction cho {target_url+'?'+post_data.decode('utf-8', errors='ignore')}\", y_pred)\n",
        "                if y_pred == 1:\n",
        "                        self.send_response(403)  # Gửi mã trạng thái 403 Forbidden\n",
        "                        self.send_header('Content-type', 'text/html')\n",
        "                        self.end_headers()\n",
        "                        html_content = '''<!DOCTYPE html>\n",
        "                                            <html lang=\"en\">\n",
        "                                            <head>\n",
        "                                                <meta charset=\"UTF-8\">\n",
        "                                                <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "                                                <title>403 Forbidden</title>\n",
        "                                            </head>\n",
        "                                            <body>\n",
        "                                                <h1>403 Forbidden</h1>\n",
        "                                                <p>Truy cập bị từ chối. Vui lòng liên hệ với quản trị viên.</p>\n",
        "                                            </body>\n",
        "                                            </html>'''\n",
        "                        self.wfile.write(html_content.encode('utf-8'))\n",
        "                        return  # Dừng xử lý và trả về              \n",
        "                \n",
        "                headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
        "                session = requests.Session()\n",
        "                \n",
        "                if \"/dvwa/login.php\" in target_url:\n",
        "                    response = session.post(target_url, data=post_data, headers=headers, allow_redirects=False)\n",
        "                    if response.status_code == 302:\n",
        "                        cookies_dict = requests.utils.dict_from_cookiejar(response.cookies)\n",
        "                    redirect_url = response.headers.get('Location')\n",
        "                    if redirect_url:\n",
        "                        response = session.get(\"http://192.168.124.173/dvwa/\" + redirect_url)\n",
        "                    self.global_cookies.update(cookies_dict)\n",
        "                elif \"/dvwa/security.php\" in target_url:\n",
        "                    response = session.post(target_url, data=post_data, headers=headers, cookies=self.global_cookies, allow_redirects=False)\n",
        "                    self.global_cookies['security'] = response.cookies.get_dict().get('security')\n",
        "                    self.global_cookies.update(self.global_cookies)\n",
        "                    redirect_url = response.headers.get('Location')\n",
        "                    if redirect_url:\n",
        "                        response = session.get(\"http://192.168.124.173/\" + redirect_url, cookies=self.global_cookies)\n",
        "                else:\n",
        "                    if self.global_cookies:\n",
        "                        response = session.post(target_url, data=post_data, headers=headers, cookies=self.global_cookies, allow_redirects=False)\n",
        "                        if response.status_code == 302:\n",
        "                            cookies_dict = requests.utils.dict_from_cookiejar(response.cookies)\n",
        "                        redirect_url = response.headers.get('Location')\n",
        "                        if redirect_url:\n",
        "                            response = session.get(\"http://192.168.124.173/\" + redirect_url)\n",
        "                self.send_response(response.status_code)\n",
        "                content_type = response.headers.get('Content-Type', 'text/html')\n",
        "                self.send_header('Content-type', content_type)\n",
        "                #self.send_header('Content-type', 'text/html')\n",
        "                self.end_headers()\n",
        "                self.wfile.write(response.content)\n",
        "            else:\n",
        "                self.send_error(404, 'Proxy route not found')\n",
        "        except Exception as e:\n",
        "            self.send_error(500, str(e))\n",
        "\n",
        "def start_proxy_server(port=8080):\n",
        "    from http.server import HTTPServer\n",
        "    server_address = ('127.0.0.1', port)\n",
        "    httpd = HTTPServer(server_address, SimpleHttpProxy)\n",
        "    print(f'Starting HTTP Proxy server on 127.0.0.1:{port}')\n",
        "    try:\n",
        "        httpd.serve_forever()\n",
        "    except KeyboardInterrupt:\n",
        "        print('Keyboard interrupt, exiting.')\n",
        "\n",
        "# Set up proxy routes\n",
        "SimpleHttpProxy.set_routes({'proxy_route': 'http://192.168.124.173/dvwa/'})\n",
        "SimpleHttpProxy.set_routes({'proxy_route': 'http://demo.testfire.net/'})\n",
        "\n",
        "# Start the proxy server\n",
        "start_proxy_server()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
            "<html><head>\n",
            "<title>404 Not Found</title>\n",
            "</head><body>\n",
            "<h1>Not Found</h1>\n",
            "<p>The requested URL /DVWA/login.php was not found on this server.</p>\n",
            "<hr>\n",
            "<address>Apache/2.2.8 (Ubuntu) DAV/2 Server at 192.168.124.173 Port 80</address>\n",
            "</body></html>\n",
            "\n",
            "[]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[77], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m user_token_html \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_token\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(user_token_html)\n\u001b[1;32m---> 12\u001b[0m user_token \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43muser_token_html\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# user_token is now [\"value='2fc5744b8190bae45673e6b91b825178'\"], get value using exec\u001b[39;00m\n\u001b[0;32m     14\u001b[0m value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "dvwa_ip = \"192.168.124.173\"\n",
        "resp = requests.get(f\"http://{dvwa_ip}/DVWA/login.php\")\n",
        "print(resp.text)\n",
        "\n",
        "# Get the session id from cookies\n",
        "phpsessid = resp.cookies.get('PHPSESSID')\n",
        "\n",
        "# Find the html containing user_token in the page text\n",
        "user_token_html = [x for x in resp.text.split('\\n') if 'user_token' in x]\n",
        "print(user_token_html)\n",
        "user_token = [x for x in user_token_html[0].split(' ') if 'value' in x]\n",
        "# user_token is now [\"value='2fc5744b8190bae45673e6b91b825178'\"], get value using exec\n",
        "value=''\n",
        "exec(user_token[0])\n",
        "\n",
        "# manually set security low as this defaults to impossible\n",
        "cookies_json = {\n",
        "    'PHPSESSID': phpsessid,\n",
        "    'security': 'low'\n",
        "}\n",
        "body = {\n",
        "    'username': 'admin',\n",
        "    'password': 'password',\n",
        "    'Login': 'Login',\n",
        "    'user_token': value\n",
        "}\n",
        "\n",
        "post_resp = requests.post(f\"http://{dvwa_ip}/DVWA/login.php\", data=body, cookies=cookies_json)\n",
        "print(post_resp.text) # prints out the \"logged in\" page (actually index.php)\n",
        "print(\"OK\") if \"Welcome to Damn Vulnerable Web Application\" in post_resp.text else print(\"ERROR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Sử dụng hàm load_data với một URL\n",
        "# url = \"http://demo.testfire.net/search.jsp?query=%3Cscript%3Ealert%281%29%3C%2Fscript%3E\"\n",
        "\n",
        "# loaded_data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
